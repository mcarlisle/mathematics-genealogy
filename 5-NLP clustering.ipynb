{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we deal with the NLP involved in clustering the training data, and so create new top-level categories (only 10, instead of the 63 that the MSC offers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of this is done in 3-NLP classification\n",
    "# - we're just packaging it here in a function.\n",
    "def get_train_valid_test_split_from_pickles(rs=42, ts=0.3):\n",
    "    \n",
    "    with open('../thesis_msc_titled_filled_20190729.pickle', 'rb') as f:\n",
    "        thesis_msc_titled_filled = pickle.load(f)\n",
    "    with open('../cleaned_combined_msc_corpus_20190729.pickle', 'rb') as f:\n",
    "        cleaned_combined_msc_corpus = pickle.load(f)\n",
    "        \n",
    "    # thesis_msc_titled_filled are for train and test.\n",
    "    # thesis_msc_titled_unfilled are for actual classification.\n",
    "    # msc titled: 220190 = 132116 filled + 88074 unfilled\n",
    "\n",
    "    X = thesis_msc_titled_filled['thesis'].copy()\n",
    "    y = thesis_msc_titled_filled['msc'].copy()\n",
    "    feature_cols = ['thesis']\n",
    "    \n",
    "    X_tv, X_test, y_tv, y_test = train_test_split(X, y, random_state=rs, test_size=ts)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, \n",
    "                                                          random_state=rs, test_size=ts)\n",
    "    print(f\"Created train-validation-test split for X, y with sizes \", end=\"\")\n",
    "    print(f\"train: {len(X_train)}, validation: {len(X_valid)}, test: {len(X_test)}.\")\n",
    "\n",
    "    # pipe.fit has problems with pandas data frames.\n",
    "    X_train_list = list(X_train)\n",
    "    X_valid_list = list(X_valid.values)\n",
    "    X_test_list  = list(X_test.values)\n",
    "\n",
    "    y_train_array = np.array(y_train)\n",
    "    y_valid_array = np.array(y_valid)\n",
    "    y_test_array  = np.array(y_test)\n",
    "\n",
    "    # Add cleaned_combined_msc_corpus to the training set.\n",
    "    for k, v in cleaned_combined_msc_corpus.items():\n",
    "        # convert this list into a dictionary into a data frame\n",
    "        # and append it to the training dataframe.\n",
    "        X_train_list.extend(v)\n",
    "        y_train_array = np.array(list(y_train_array) + [k]*len(v))\n",
    "    \n",
    "    print(f\"After adding to train: train-validation-test split for X, y with sizes \", end=\"\")\n",
    "    print(f\"train: {len(X_train)}, validation: {len(X_valid)}, test: {len(X_test)}.\")\n",
    "\n",
    "    return X_train_list, X_valid_list, X_test_list, y_train_array, y_valid_array, y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../custom_stop_words.pickle', 'rb') as f:\n",
    "    stop_words = pickle.load(f)\n",
    "    \n",
    "# interestingly enough, we keep getting German and French words coming out in topics.\n",
    "more_stop_words = ['modles', 'berechnung', 'zum', 'quelques', 'contribution', \n",
    "                   'untersuchungen', 'thorie', 'tude', 'quations', 'etude', \n",
    "                   'aux', 'self', 'systmes', 'van', 'analyse']\n",
    "stop_words = stop_words.union(more_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train-validation-test split for X, y with sizes train: 64741, validation: 27747, test: 39638.\n"
     ]
    }
   ],
   "source": [
    "X_train_list, X_valid_list, X_test_list, \\\n",
    "    y_train_array, y_valid_array, y_test_array = get_train_valid_test_split_from_pickles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203580, 27747, 39638, 203580, 27747, 39638)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_list), len(X_valid_list), len(X_test_list), \\\n",
    "    len(y_train_array), len(y_valid_array), len(y_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   47.2s remaining:   47.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   47.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   47.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   42.0s remaining:   42.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   42.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   42.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   35.8s remaining:   35.8s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   37.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   37.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   39.7s remaining:   39.7s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   40.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   40.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   50.7s remaining:   50.7s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   52.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   52.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   43.3s remaining:   43.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   44.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   44.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 6 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   32.3s remaining:   32.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   32.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   32.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 7 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   24.6s remaining:   24.6s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   25.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   25.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 8 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   22.6s remaining:   22.6s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   23.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   23.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   27.6s remaining:   27.6s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   28.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   28.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   22.3s remaining:   22.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   22.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   22.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=-1,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/limericking-part-2-topic-modeling-with-lda-45476ab9af15\n",
    "# thanks Max!\n",
    "\n",
    "# we run the LDA multiple times, each time we get a topic with more non-English words \n",
    "# to add to the stop words list.\n",
    "\n",
    "#sklearn makes it easy to vectorize and perform LDA:\n",
    "#cv = CountVectorizer(max_df=.8, min_df=3, stop_words='english')\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "vectors = cv.fit_transform(X_train_list)\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=10, n_jobs=-1, verbose=20)\n",
    "LDA.fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the LDA model!\n",
    "#with open('cv_10topics.pickle', 'wb') as f:\n",
    "#    pickle.dump(cv, f)\n",
    "#with open('LDA_10topics.pickle', 'wb') as f:\n",
    "#    pickle.dump(LDA, f)\n",
    "#with open('vectors_10topics.pickle', 'wb') as f:\n",
    "#    pickle.dump(vectors, f)\n",
    "with open('cv_10topics.pickle', 'rb') as f:\n",
    "    cv = pickle.load(f)\n",
    "with open('LDA_10topics.pickle', 'rb') as f:\n",
    "    LDA = pickle.load(f)\n",
    "with open('vectors_10topics.pickle', 'rb') as f:\n",
    "    vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76860"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LDA.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['regression', 'based', 'using', 'time', 'inference', 'bayesian', 'applications', 'model', 'random', 'statistical', 'methods', 'estimation', 'analysis', 'data', 'models']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['approach', 'algorithms', 'time', 'programming', 'analysis', 'methods', 'optimal', 'theory', 'processes', 'applications', 'optimization', 'stochastic', 'problems', 'control', 'systems']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['decision', 'methods', 'waves', 'phase', 'models', 'fluid', 'mathematical', 'study', 'modeling', 'simulation', 'analysis', 'flows', 'numerical', 'dynamics', 'flow']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['empirical', 'international', 'trade', 'analysis', 'growth', 'labor', 'markets', 'effects', 'financial', 'policy', 'theory', 'market', 'economics', 'economic', 'essays']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['complex', 'hilbert', 'space', 'classes', 'algebraic', 'cohomology', 'modules', 'algebra', 'properties', 'curves', 'rings', 'surfaces', 'spaces', 'operators', 'functions']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['algbres', 'untersuchung', 'systeme', 'au', 'problemas', 'anwendung', 'avec', 'calcul', 'lie', 'beitrag', 'sobre', 'varits', 'groupes', 'fonctions', 'espaces']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['lie', 'topological', 'dimensional', 'applications', 'properties', 'group', 'field', 'structures', 'manifolds', 'groups', 'geometry', 'quantum', 'algebras', 'spaces', 'theory']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #7\n",
      "['value', 'theory', 'elliptic', 'numerical', 'partial', 'boundary', 'nonlinear', 'order', 'finite', 'methods', 'solutions', 'graphs', 'differential', 'problems', 'equations']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #8\n",
      "['ad', 'linaires', 'ordnung', 'domain', 'galois', 'differentialgleichungen', 'bercksichtigung', 'aus', 'combinatorics', 'funktionen', 'finite', 'abelian', 'subgroups', 'representations', 'groups']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #9\n",
      "['wireless', 'algorithms', 'processing', 'applications', 'network', 'distributed', 'analysis', 'data', 'performance', 'information', 'learning', 'design', 'based', 'systems', 'networks']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_keywords = 15\n",
    "#And to demonstrate what the topics it finds look like:\n",
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f'THE TOP {num_keywords} WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-num_keywords:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to save the topic keywords:\n",
    "topic_keywords = []\n",
    "for index,topic in enumerate(LDA.components_):\n",
    "    topic_keywords.append([cv.get_feature_names()[i] for i in topic.argsort()[-num_keywords:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('10topics_15keywords_20190729_3.pickle', 'wb') as f:\n",
    "#    pickle.dump(topic_keywords, f)\n",
    "with open('10topics_15keywords_20190729_3.pickle', 'rb') as f:\n",
    "    LDA_topic_keywords = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   49.0s remaining:   49.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   49.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   49.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   56.1s remaining:   56.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   57.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   57.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   41.5s remaining:   41.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   42.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   42.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   34.7s remaining:   34.7s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   35.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   35.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   34.0s remaining:   34.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   34.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   34.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   31.7s remaining:   31.7s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   32.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   32.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 6 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   33.8s remaining:   33.8s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   34.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   34.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 7 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   30.3s remaining:   30.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   30.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   30.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 8 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   29.0s remaining:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   29.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   29.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   25.0s remaining:   25.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   25.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   25.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   21.4s remaining:   21.4s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   21.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   21.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   17.1s remaining:   17.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   17.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   17.5s finished\n"
     ]
    }
   ],
   "source": [
    "lda_ft = LDA.fit_transform(vectors)  # before all we did was fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 203580 samples in 0.278s...\n",
      "[t-SNE] Computed neighbors for 203580 samples in 128.642s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 27000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 28000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 29000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 30000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 31000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 32000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 33000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 34000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 35000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 36000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 37000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 38000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 39000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 40000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 41000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 42000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 43000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 44000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 45000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 46000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 47000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 48000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 49000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 50000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 51000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 52000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 53000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 54000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 55000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 56000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 57000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 58000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 59000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 60000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 61000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 62000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 63000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 64000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 65000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 66000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 67000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 68000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 69000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 70000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 71000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 72000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 73000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 74000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 75000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 76000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 77000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 78000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 79000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 80000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 81000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 82000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 83000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 84000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 85000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 86000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 87000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 88000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 89000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 90000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 91000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 92000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 93000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 94000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 95000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 96000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 97000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 98000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 99000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 100000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 101000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 102000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 103000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 104000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 105000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 106000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 107000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 108000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 109000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 110000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 111000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 112000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 113000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 114000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 115000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 116000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 117000 / 203580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 118000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 119000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 120000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 121000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 122000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 123000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 124000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 125000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 126000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 127000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 128000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 129000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 130000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 131000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 132000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 133000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 134000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 135000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 136000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 137000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 138000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 139000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 140000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 141000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 142000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 143000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 144000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 145000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 146000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 147000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 148000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 149000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 150000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 151000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 152000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 153000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 154000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 155000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 156000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 157000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 158000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 159000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 160000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 161000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 162000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 163000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 164000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 165000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 166000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 167000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 168000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 169000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 170000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 171000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 172000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 173000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 174000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 175000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 176000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 177000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 178000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 179000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 180000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 181000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 182000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 183000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 184000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 185000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 186000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 187000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 188000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 189000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 190000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 191000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 192000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 193000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 194000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 195000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 196000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 197000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 198000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 199000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 200000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 201000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 202000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 203000 / 203580\n",
      "[t-SNE] Computed conditional probabilities for sample 203580 / 203580\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 96.649193\n",
      "[t-SNE] KL divergence after 1000 iterations: 3.182844\n"
     ]
    }
   ],
   "source": [
    "# Now to visualize the LDA via TSNE?\n",
    "\n",
    "# https://shuaiw.github.io/2016/12/22/topic-modeling-and-tsne-visualzation.html\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "# possibly use TruncatedSVD next time? this is taking a while to run w/o verbosity\n",
    "\n",
    "# many-many-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(lda_ft)  # lda_ft is called X_topics in the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tsne_lda_20190730.pickle', 'wb') as f:\n",
    "    pickle.dump(tsne_lda, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lda_ft_20190730.pickle', 'wb') as f:\n",
    "    pickle.dump(lda_ft, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.plotting import save\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "n_top_words = 15 # number of keywords we show\n",
    "\n",
    "# 20 colors\n",
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\",\n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\",\n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lda_keys = []\n",
    "for i in range(lda_ft.shape[0]):\n",
    "    _lda_keys +=  lda_ft[i].argmax(), \n",
    "    # the LDA key topic is the index with the largest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also found this piece in https://pythonhosted.org/lda/\n",
    "\n",
    "topic_summaries = []\n",
    "#topic_word = LDA.topic_word_  # all topic words\n",
    "topic_word = LDA.components_  # all topic words... but not really\n",
    "vocab = cv.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "    topic_summaries.append(' '.join(topic_words)) # append!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203580, 203580)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(X_train_list[:10])\n",
    "#print(_lda_keys[:10])\n",
    "#colormap[_lda_keys][:num_example]\n",
    "len(tsne_lda[:, 0]), len(X_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = list(np.array(X_train_list))\n",
    "_lda_keys = list(np.array(_lda_keys))\n",
    "x = tsne_lda[:, 0]\n",
    "y = tsne_lda[:, 1]\n",
    "colormap = colormap[_lda_keys]\n",
    "\n",
    "\n",
    "# if we wish to see fewer points, use these \"cuts\"\n",
    "threshold = 0.5\n",
    "_idx = np.amax(lda_ft, axis=1) > threshold  # idx of doc that above the threshold\n",
    "lda_ft_cut = lda_ft[_idx]\n",
    "\n",
    "X_train_list_cut = list(np.array(X_train_list)[_idx])\n",
    "_lda_keys_cut = list(np.array(_lda_keys)[_idx])\n",
    "x_cut = tsne_lda[:, 0][_idx]\n",
    "y_cut = tsne_lda[:, 1][_idx]\n",
    "colormap_cut = colormap[_lda_keys][_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.models.renderers.GlyphRenderer\">GlyphRenderer</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'26812', <span id=\"26815\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">data_source&nbsp;=&nbsp;ColumnDataSource(id='26808', ...),</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">glyph&nbsp;=&nbsp;Scatter(id='26810', ...),</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hover_glyph&nbsp;=&nbsp;None,</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">level&nbsp;=&nbsp;'glyph',</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted&nbsp;=&nbsp;False,</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted_glyph&nbsp;=&nbsp;None,</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">nonselection_glyph&nbsp;=&nbsp;Scatter(id='26811', ...),</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">selection_glyph&nbsp;=&nbsp;None,</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">view&nbsp;=&nbsp;CDSView(id='26813', ...),</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range_name&nbsp;=&nbsp;'default',</div></div><div class=\"26814\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range_name&nbsp;=&nbsp;'default')</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  var expanded = false;\n",
       "  var ellipsis = document.getElementById(\"26815\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    var rows = document.getElementsByClassName(\"26814\");\n",
       "    for (var i = 0; i < rows.length; i++) {\n",
       "      var el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "GlyphRenderer(id='26812', ...)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Mathematics Genealogy Project: LDA t-SNE PCA of 10 topics in 2 dimensions'\n",
    "filename = 'MGP_topics_LDA_viz'\n",
    "num_example = len(lda_ft)\n",
    "\n",
    "plot_lda = bp.figure(plot_width=1200, plot_height=1000,\n",
    "                     title=title,\n",
    "#                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "                     tools=\"pan,wheel_zoom,box_zoom,reset,previewsave\",\n",
    "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "plot_lda.scatter(x='x', y='y', fill_color='color', fill_alpha=0.6, line_color=None,\n",
    "                 source=bp.ColumnDataSource({\n",
    "                   \"x\": x, \"y\": y, \"color\": colormap,\n",
    "                   \"content\": X_train_list, # all of it was [:num_example]\n",
    "                   \"topic_key\": _lda_keys\n",
    "                   }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michael/Dropbox/code/Flatiron School/042219/mod7-final/write-up/MGP_topics_LDA_viz.html'"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly choose a title (within a topic) coordinate as the crucial words coordinate\n",
    "topic_coord = np.empty((lda_ft.shape[1], 2)) * np.nan\n",
    "for topic_num in _lda_keys:\n",
    "    if not np.isnan(topic_coord).any():\n",
    "        break\n",
    "    topic_coord[topic_num] = tsne_lda[_lda_keys.index(topic_num)]\n",
    "\n",
    "# plot crucial words\n",
    "for i in range(lda_ft.shape[1]):\n",
    "    split_topic = topic_summaries[i].split(' ')\n",
    "    half = len(split_topic) // 2\n",
    "    print_text = ' '.join(split_topic[:half]) + '\\n' + ' '.join(split_topic[half:])\n",
    "#    plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [topic_summaries[i]])\n",
    "    plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [print_text])\n",
    "#    print(print_text)\n",
    "\n",
    "    \n",
    "# hover tools\n",
    "#hover = plot_lda.select(dict(type=HoverTool))\n",
    "#hover.tooltips = {\"content\": \"@content - topic: @topic_key\"}\n",
    "\n",
    "# save the plot\n",
    "save(plot_lda, '{}.html'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way we can do clustering is with k-means clustering. \n",
    "# Let's see if we get similar results.\n",
    "\n",
    "# k-means clustering for vectorized documents, with truncated SVD\n",
    "\n",
    "kmeans_steps = [('count', CountVectorizer(stop_words=stop_words)),     # vectorize,\n",
    "                ('svd', TruncatedSVD(random_state=42)),                # reduce dimensionality, \n",
    "                ('kmeans', KMeans(n_clusters=10, n_jobs=-1, n_init=10, # then cluster\n",
    "                                  random_state=42, verbose=10))]\n",
    "kmeans_pipe = Pipeline(steps=kmeans_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pipe.fit(X_train_list) # Run the clustering algorithm\n",
    "cluster_assignments = kmeans_pipe.predict(X_valid_list) # Generate cluster index values for each row in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27747, 27747)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_assignments), len(X_valid_list) \n",
    "# we have 10 clusters for the validation set.\n",
    "# we can spot check them to decide what these clusters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_cluster_df = pd.DataFrame(data={'thesis': X_valid_list, 'cluster': cluster_assignments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_valid_cluster_df.head()\n",
    "#X_valid_cluster_df[X_valid_cluster_df['cluster']==6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is no good way to visualize k-means, we can compare the overlap of different topics.\n",
    "\n",
    "Let's get the clusters for X_test_list for both k-means and LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_test_kmeans = kmeans_pipe.predict(X_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   10.4s remaining:   10.4s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   10.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    5.8s remaining:    5.8s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    4.8s remaining:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    5.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    4.1s remaining:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    3.8s remaining:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 6 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    3.2s remaining:    3.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 7 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    4.2s remaining:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 8 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    3.4s remaining:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    2.1s remaining:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "vectors_test = cv.fit_transform(X_test_list)\n",
    "lda_test = LDA.fit_transform(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_test_lda = []\n",
    "for i in range(lda_test.shape[0]):\n",
    "    cluster_test_lda += lda_test[i].argmax(),\n",
    "    # the LDA key topic is the index with the largest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39638, 39638)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_test_kmeans), len(cluster_test_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 8, 0, 1, 4, 8, 8, 0, 8, 0, 4, 8, 5, 4, 8, 0, 1, 0, 8],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_test_kmeans[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 7, 9, 0, 1, 7, 9, 9, 3, 7, 7, 7, 9, 3, 8, 9, 2, 3, 6, 6]"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_test_lda[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 39,638 titles in the testing set. On how many do LDA and k-means agree on clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list of lists holding the indices of each cluster\n",
    "cluster_test_kmeans_index = []\n",
    "cluster_test_lda_index = []\n",
    "for i in range(10):\n",
    "    cluster_test_kmeans_index.append(set())  # use sets, b/c indices are unique\n",
    "    cluster_test_lda_index.append(set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cluster_test_kmeans)):\n",
    "    cluster_test_kmeans_index[cluster_test_kmeans[i]].add(i)\n",
    "    cluster_test_lda_index[cluster_test_lda[i]].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the index lists for each of the 10 clusters \n",
    "# in each of the two clustering methods.\n",
    "\n",
    "# Now we compare the intersections of each pairing and find \n",
    "# the highest percentages, to measure how much the two \n",
    "# clusterings \"agree\".\n",
    "\n",
    "count_overlap = []\n",
    "# count_overlap[i][j] contains a triple:\n",
    "# (len(kmeans[i]), len(lda[j]), len(intersection)))\n",
    "\n",
    "for i in range(10):\n",
    "    count_overlap.append([])\n",
    "    for j in range(10):\n",
    "        intersect = cluster_test_kmeans_index[i].intersection(cluster_test_lda_index[j])\n",
    "        count_overlap[i].append((len(cluster_test_kmeans_index[i]), \n",
    "                                 len(cluster_test_lda_index[j]), \n",
    "                                 len(intersect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7706, 3794, 987),\n",
       " (7706, 2754, 514),\n",
       " (7706, 5749, 1344),\n",
       " (7706, 8932, 2063),\n",
       " (7706, 2732, 390),\n",
       " (7706, 3260, 551),\n",
       " (7706, 2768, 515),\n",
       " (7706, 3837, 521),\n",
       " (7706, 2657, 375),\n",
       " (7706, 3155, 446)]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which of the LDA's clusters does the first cluster of k-means agree with?\n",
    "count_overlap[0]\n",
    "# Seemingly, none of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the two clustering methods came up with completely different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kmeans_lda_cluster_overlap_sizes.pickle', 'wb') as f:\n",
    "    pickle.dump(count_overlap, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
